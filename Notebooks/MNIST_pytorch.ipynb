{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683be6a8",
   "metadata": {},
   "source": [
    "# Распознование рукописных цифр (MNIST) с помощью Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5fbd16",
   "metadata": {},
   "source": [
    "### 1. Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2e6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms\n",
    "import torch.utils.data\n",
    "import torch.nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2878b51",
   "metadata": {},
   "source": [
    "### 2. Загрузка набора данных MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb20ea",
   "metadata": {},
   "source": [
    "__Скачивание данных в текущую директорию:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abe0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a0049",
   "metadata": {},
   "source": [
    "__Чтение тренировочной и тестовой выборок набора данных MNIST :__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc1e48",
   "metadata": {},
   "source": [
    "Данные представляются в виде пар __(tuple)__, где первый элемент — изображение в формате __PIL.Image.Image__, а второй — целочисленная метка класса. Параметр __transform__ обеспечивает преобразование изображений в формат __torch.Tensor__ для последующей работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e8d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = dir_name, train = True,\n",
    "download = True, transform = torchvision.transforms.ToTensor())\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = dir_name, train = False,\n",
    "download = True, transform = torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c26cb",
   "metadata": {},
   "source": [
    "__Зададим размер обрабатываемой пачки данных:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96454502",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89296b70",
   "metadata": {},
   "source": [
    "__Создадим объекты для последовательной загрузки пачек данных из тренировочной и тестовой выборок:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6e635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246e71f",
   "metadata": {},
   "source": [
    "### 3. Создание модели, соответствующей логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a68430",
   "metadata": {},
   "source": [
    "__Количество входных нейронов:__ 28 * 28 = 784, поскольку изображения имеют размер 28 на 28 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1eb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 28 * 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f44ca9",
   "metadata": {},
   "source": [
    "__Количество выходных нейронов:__ 10, поскольку всего 10 классов (цифры от 0 до 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa39367",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f1b9f",
   "metadata": {},
   "source": [
    "__Создадим класс сети, соответствующей логистической регрессии:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3b058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    # Объявление конструктора\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Создание полносвязного слоя\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    # Переопределение метода, вызываемого в процессе прямого прохода\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ce67b",
   "metadata": {},
   "source": [
    "__Создадим объект разработанного класса:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62363f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_nn = LogisticRegressionModel(image_resolution, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f8f69",
   "metadata": {},
   "source": [
    "### 3. Обучение построенной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2f5ea",
   "metadata": {},
   "source": [
    "__Зададим скорость обучения модели:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6119b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cda59d",
   "metadata": {},
   "source": [
    "__Зададим количество эпох обучения модели:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97c604ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657d902",
   "metadata": {},
   "source": [
    "__Выберем и зададим устройство для вычислений:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6001511b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logreg_nn.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78281a",
   "metadata": {},
   "source": [
    "__Выберем функцию ошибки на этапе обучения:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b7f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7517b",
   "metadata": {},
   "source": [
    "__Выберем метод оптимизации для обучения параметров:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e99e6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(logreg_nn.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9d52c",
   "metadata": {},
   "source": [
    "__Обучим модель:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70258985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(num_epochs): # проход по эпохам\n",
    "    for i, (images, labels) in enumerate(train_data_loader): # проход по изображениям\n",
    "        \n",
    "        # Преобразование тензора [B, C, W, H] к формату [B, W * H]\n",
    "        # (images.shape=[B, C, W, H], B - размер пачки, C = 1 - число каналов,\n",
    "        # W, H - ширина и высота изображений в пачке)\n",
    "        # и загрузка данных на устройство\n",
    "        images = images.view(-1, image_resolution).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = logreg_nn(images) # вычисление выхода сети\n",
    "        loss = loss_function(outputs, labels) # вычисление ошибки\n",
    "        \n",
    "        # Обратный проход\n",
    "        optimizer.zero_grad() # обнуление всех вычисляемых градиентов\n",
    "        loss.backward() # вычисление градиента функции ошибки\n",
    "        optimizer.step() # обновление параметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca495a",
   "metadata": {},
   "source": [
    "__Зададим функцию вычисления точности top-1:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1a791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data_loader, model):\n",
    "    tp = 0\n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad(): # деактивация вычисления градиентов\n",
    "        for images, labels in data_loader: # проход по всем данным\n",
    "            \n",
    "            # Конвертация тензора [B, C, W, H] к формату [B, W * H]\n",
    "            images = images.reshape(-1, image_resolution)\n",
    "            \n",
    "            outputs = model(images) # выход сети\n",
    "            \n",
    "            # Выбор предсказанных меток с максимальной достоверностью.\n",
    "            # outputs.data - объект типа torch.tensor, двумерный тензор,\n",
    "            # вектора достоверности принадлежности каждому из 10\n",
    "            # допустимых классов (размерность 0 - номер изображения\n",
    "            # в пачке, размерность 1 - номер класса); predicted - объект\n",
    "            # типа torch.tensor (одномерный тензор меток классов).\n",
    "            # Выбор максимальных значений по первой размерности\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            n += labels.size(0) # количество изображений (= batch_size)\n",
    "            \n",
    "            tp += (predicted == labels).sum() # количество совпадений\n",
    "\n",
    "    return tp / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499eff2a",
   "metadata": {},
   "source": [
    "### 4. Тестирование обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389e936",
   "metadata": {},
   "source": [
    "__Логирование метрики качества на тренировочных данных:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a58fba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9045000076293945\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(get_accuracy(test_data_loader,logreg_nn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
